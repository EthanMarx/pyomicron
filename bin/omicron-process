#!/usr/bin/env python

"""Process Omicron triggers online for LIGO
"""

import argparse
import os
import sys
import shutil
from time import sleep
from glob import glob
from getpass import getuser

# python 3
try:
    import configparser
# python 2
except ImportError:
    import ConfigParser as configparser

from glue import pipeline

from omicron import (const, segments, log, data, parameters, utils, condor)

logger = log.Logger('omicron-process')

# -- parse command line
parser = argparse.ArgumentParser(description=__doc__)

parser.add_argument('group', help='name of configuration group to process')
parser.add_argument('-f', '--config-file', default=const.OMICRON_CHANNELS_FILE,
                    help='path to configuration file, default: %(default)s')
parser.add_argument('-i', '--ifo', default=const.IFO,
                    help='IFO prefix to process, default: %(default)s')
parser.add_argument('-t', '--gps', nargs=2, type=int,
                    help='GPS times for offline processing')

outg = parser.add_argument_group('Output options')
outg.add_argument('-o', '--output-dir',
                  help='path to output directory, '
                       'default under ~/Omicron/Prod somewhere')

condorg = parser.add_argument_group('Condor options')
condorg.add_argument('--no-submit', action='store_true', default=False,
                     help='do not submit the DAG to condor, '
                          'default: %(default)s')
condorg.add_argument('--universe', default='vanilla',
                     help='condor universe, default: %(default)s')
condorg.add_argument('--executable', default=utils.which('omicron.exe'),
                     help='omicron executable, default: %(default)s')
condorg.add_argument('--condor-retry', type=int, default=2,
                     help='number of times to retry each job if failed, '
                          'default: %(default)s')
condorg.add_argument('--condor-accounting-group',
                     default='ligo.dev.o1.detchar.transient.omicron',
                     help='accounting_group for condor submission on the LIGO '
                          'Data Grid, default: %(default)s')
condorg.add_argument('--condor-accounting-group-user', default=getuser(),
                     help='accounting_group_user for condor submission on the '
                          'LIGO Data Grid, default: %(default)s')
condorg.add_argument('--submit-rescue-dag', type=int, default=0,
                     help='number of times to automatically submit the '
                          'rescue DAG, default: %(default)s')

args = parser.parse_args()

if args.ifo is None:
    raise parser.error("Cannot determine IFO prefix from sytem"
                       ", please pass --ifo on the command line")
ifo = args.ifo
llhoft = data.ligo_low_latency_hoft_type(ifo)
group = args.group
online = args.gps is None

logger.info("--- Welcome to the Omicron processor ---")

# -- parse configuration file and get parameters ------------------------------

cp = configparser.ConfigParser()
cp.read(args.config_file)

# validate
if not cp.has_section(group):
    raise configparser.NoSectionError(group)

# get params
frametype = cp.get(group, 'frametype')
logger.debug("frametype = %s" % frametype)
chunkdur = cp.getint(group, 'chunk-duration')
logger.debug("chunkdur = %s" % chunkdur)
segdur = cp.getint(group, 'segment-duration')
logger.debug("segdur = %s" % segdur)
overlap = cp.getint(group, 'overlap-duration')
logger.debug("overlap = %s" % overlap)
if overlap % 2:
    raise ValueError("Cannot proceed with odd overlap (%d seconds)" % overlap)
padding = int(overlap / 2)
logger.debug("padding = %s" % padding)
try:
    stateflag = cp.get(group, 'state-flag')
except configparser.NoOptionError:
    statechannel = None
else:
    logger.debug("State flag = %s" % stateflag)
    try:
        statechannel = segments.STATE_CHANNEL[stateflag]
    except KeyError as e:
        e.args = ('Cannot map state flag %r to channel' % stateflag,)
        raise
    logger.debug("State channel = %s" % statechannel)

if online and not args.output_dir:
    args.output_dir = os.path.join(const.OMICRON_PROD, group)
elif not args.output_dir:
    start, end = args.gps
    args.output_dir = os.path.join(
        const.OMICRON_PROD, '%s-%d-%d' % (group, start, end))
rundir = os.path.abspath(args.output_dir)

# -- find run segment

segfile = os.path.join(rundir, 'segments.txt')
if online:
    if frametype == '%s_HOFT_C00' % ifo:
        end = data.get_latest_data_gps(ifo, llhoft)
    else:
        end = data.get_latest_data_gps(ifo, frametype)
    end -= padding
    try:
        start = segments.get_last_run_segment(segfile)[1]
    except IOError:
        logger.debug("No online segment record, starting with 4000 seconds")
        start = end - 4000
    else:
        logger.debug("Online segment record recovered")
else:
    start, end = args.gps
    rundir = args.output_dir or os.path.join(
        const.OMICRON_PROD, '%s-%d-%d' % (group, start, end))
rundir = os.path.abspath(rundir)
segfile = os.path.join(rundir, 'segments.txt')

duration = end - start
datastart = start - padding
dataend = end + padding
dataduration = dataend - datastart

logger.info("Processing segment determined as")
logger.info("    %d %d" % (datastart, dataend))
logger.info("Duration = %d seconds" % dataduration)

span = (start, end)

# -- double-check frametype for h(t)
# don't use aggregated h(t) if running online

if frametype == '%s_HOFT_C00' % ifo:
    try:
        data.check_data_availability(ifo, frametype, start, end)
    except RuntimeError:
        msg = ("Gaps found in %s availability, turning to %s"
               % (frametype, llhoft))
        if online:
            logger.debug(msg)
        else:
            logger.warning(msg)
        frametype = llhoft

# -- set directories and check for an existing process ------------------------

if not os.path.isdir(rundir):
    os.makedirs(rundir)
logger.info("Using run directory\n%s" % rundir)

if os.path.isfile(os.path.join(rundir, 'omicron.dag.lock')):
    raise RuntimeError("omicron.dag.lock found in %s, DAG already running"
                       % rundir)

# -- find segments and frame files --------------------------------------------

# validate span is long enough
if dataduration < chunkdur:
    logger.info("Segment is too short (%d < %d), please try again later"
             % (duration, chunkdur - padding * 2))
    sys.exit(0)

# find run segments
if statechannel:
    logger.info("Finding segments for relevant state...")
    segs = segments.get_state_segments(statechannel, frametype,
                                       datastart, dataend)
else:
    segs = segments.get_frame_segments(ifo, frametype, datastart, dataend)

if len(segs):
    logger.info("State/frame segments recovered as")
    for seg in segs:
        logger.info("    %d %d" % seg)
    logger.info("Duration = %d seconds" % abs(segs))

# truncate final segment if running online
try:
    lastseg = segs[-1]
except IndexError:
    truncate = False
else:
    truncate = online and lastseg[1] == dataend

# if segment is shorter than one chunk, leave it until later
if truncate and (
        (not statechannel and abs(lastseg) < chunkdur) or
        (statechannel and abs(lastseg) < (chunkdur + segdur))):
    logger.info("The final segment is too short, but ends at the limit of "
                "available data, presumably this is an active segment. "
                "It will be removed so that it can be "
                "processed properly later")
    segs = segs[:-1]
    dataend = lastseg[0]
# if long enough and no state required, restrict to an integer number of chunks
elif truncate and (not statechannel or abs(lastseg) >= (chunkdur + segdur)):
    logger.info("Truncating to process only complete chunks...")
    t, e = lastseg
    step = chunkdur - overlap
    while t + chunkdur <= e:
        t += step
    segs[-1] = type(segs[-1])(lastseg[0], t + overlap)
    dataend = segs[-1][1]
    logger.info("This analysis will now run to %d" % dataend)

dataspan = type(segs)([segments.Segment(datastart, dataend)])

# find the frames
cache = data.find_frames(ifo, frametype, datastart, dataend, on_gaps='warn')
if not online and len(cache) == 0:
    raise RuntimeError("No frames found for %s-%s" % (ifo[0], frametype))
try:
    cachesegs = (segments.cache_segments(cache) & dataspan).coalesce()
except TypeError:
    alldata = False
else:
    alldata = cachesegs == dataspan

# if all of the data are available, but no segments, record segments.txt
if len(segs) == 0 and online and alldata:
    logger.info("No segments found, but all data are available. "
                "A segments.txt file will be written so we don't have to "
                "search these data again")
    segments.write_segments(cachesegs, segfile)
    logger.info("Segments written to\n%s" % segfile)
    sys.exit(0)
# otherwise not all data are available, so 
elif len(segs) == 0 and online:
    logger.info("No segments found, please try again later")
    sys.exit(0)
elif len(segs) == 0:
    raise RuntimeError("No segments found")

# apply minimum duration requirement
segs = type(segs)(s for s in segs if abs(s) >= segdur)
# and calculate trigger output segments
trigsegs = type(segs)(type(s)(*s) for s in segs).contract(padding)

# display segments
logger.info("Final data segments selected as")
for seg in segs:
    logger.info("    %d %d" % seg)
logger.info("Duration = %d seconds" % abs(segs))

span = type(trigsegs)([trigsegs.extent()])

logger.info("This will output triggers for")
for seg in trigsegs:
    logger.info("    %d %d" % seg)
logger.info("Duration = %d seconds" % abs(trigsegs))


# write cache
cachefile = os.path.join(rundir, 'frames.lcf')
data.write_cache(cache, cachefile)

# -- make parameters files then generate the DAG ------------------------------

# generate a 'master' parameters.txt file for archival purposes
tmpparfile = parameters.generate_parameters_files(cp, group, cachefile, rundir,
                                                  channellimit=int(1e8))[0]
parfile = os.path.join(rundir, 'parameters.txt')
logger.debug("Create master parameters file\n%s" % parfile)
shutil.move(tmpparfile, parfile)

# then generate actual parameters files for submission (channel groups)
jobfiles = parameters.generate_parameters_files(cp, group, cachefile, rundir)

logdir = os.path.join(rundir, 'logs')
if not os.path.isdir(logdir):
    os.mkdir(logdir)

dag = pipeline.CondorDAG(os.path.join(logdir, 'omicron.log'))
dag.set_dag_file(os.path.join(rundir, 'omicron'))

job = pipeline.CondorDAGJob(args.universe, args.executable)
job.set_sub_file(os.path.join(rundir, 'omicron.sub'))
job.set_log_file(os.path.join(logdir, 'omicron-$(cluster)-$(process).log'))
job.set_stderr_file(os.path.join(logdir, 'omicron-$(cluster)-$(process).err'))
job.set_stdout_file(os.path.join(logdir, 'omicron-$(cluster)-$(process).out'))
job.add_condor_cmd('getenv', 'True')
job.add_condor_cmd('accounting_group', args.condor_accounting_group)
job.add_condor_cmd('accounting_group_user', args.condor_accounting_group_user)
job.add_condor_cmd('+OmicronGroup', '"%s"' % group)

for s, e in segs:
    for pf in jobfiles:
        node = pipeline.CondorDAGNode(job)
        node.set_category('omicron')
        node.set_retry(str(args.condor_retry))
        node.add_var_arg(str(s))
        node.add_var_arg(str(e))
        node.add_var_arg(os.path.abspath(pf))
        dag.add_node(node)
dag.write_sub_files()
dag.write_dag()
dag.write_script()
logger.info("Dag with %d nodes written to" % len(dag.get_nodes()))
dagfile = dag.get_dag_file()
print(os.path.abspath(dagfile))

if args.no_submit:
    sys.exit(0)

# -- submit the DAG and babysit -----------------------------------------------

# submit DAG
logger.info("--- Submitting DAG to condor -------")

for i in range(args.submit_rescue_dag + 1):
    dagid = condor.submit_dag(dagfile, force=i==0)
    logger.info("Condor ID = %d" % dagid)
    logger.debug("Sleep for 15 seconds while DAGMan starts up")
    sleep(15)
    # find lock file and monitor
    logger.info("Monitoring DAG via ID...")
    states = ['ready', 'queued', 'failed', 'done']
    colors = ['white', 'blue', 'red', 'green']
    old = dict((k, -1) for k in states)
    logger.debug("Dag Status (%d nodes total):" % (len(dag.get_nodes())))
    logger.debug('-' * 40)
    logger.debug('  {0} |  {1} |  {2} |    {3}'.format(
             *[log.color_text(s, c) for s, c in zip(states, colors)]))
    logger.debug('-' * 40)
    for job in condor.iterate_dag_status(dagid):
        for state in states:
            if job[state] != old[state]:
                logger.debug(' | '.join(['%7s' % job[s] for s in states]))
                break
        old = job
    logger.debug('-' * 40)
    logger.info("DAG has exited with status %d" % job['exitcode'])
    if job['exitcode'] == 0:
        break
    elif i == args.submit_rescue_dag + 1:
        raise RuntimeError("DAG has failed to complete %d times"
                           % args.submit_rescue_dag + 1)
    else:
        rescue = condor.find_rescue_dag(dagfile)
        logger.warning("Rescue DAG %s was generated" % rescue)

# write segments
segments.write_segments(span, segfile)
logger.info("Segments written to\n%s" % segfile)

# archive files
stub = '%d-%d' % (start, end)
for f in ['%s.dagman.out' % dagfile, segfile, cachefile, parfile]:
    base, ext = os.path.splitext(os.path.basename(f))
    archive = os.path.join(logdir, '%s-%s%s' % (base, stub, ext))
    shutil.copyfile(f, archive)
    logger.debug("Archived file\n%s --> %s" % (f, archive))

# clean up temporary files
for ffl in glob(os.path.join(rundir, 'triggers', 'ffconvert.*.ffl')):
    os.remove(ffl)
    logger.debug('Deleted file %r' % ffl)

# and exit
logger.info("---- Processing complete -----------")
